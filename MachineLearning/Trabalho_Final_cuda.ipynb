{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oCKpmgTjB_Vu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7f326aa-d5b4-4b2b-dc6a-844d07fc4787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim, no_grad\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from matplotlib.pyplot import imshow\n",
        "from time import time\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "from sklearn.metrics import mean_absolute_error as MAE"
      ],
      "metadata": {
        "id": "tN_Zvv0dCh4x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoF6JsVvNJ1d",
        "outputId": "d68cd68d-571e-4593-f608-f8f7eda4946b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MNIST_treino = datasets.MNIST('./', train = True, transform = transforms.ToTensor(), download=True)\n",
        "MNIST_teste =  datasets.MNIST('./', train = False, transform = transforms.ToTensor(), download=False)"
      ],
      "metadata": {
        "id": "o4W_59-TESk_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d06d1deb-261f-49a6-a142-1093f3ef9d22"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 157567313.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 105427061.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 138000426.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 21073593.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nova secção"
      ],
      "metadata": {
        "id": "kC8vDFtTRlt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(MNIST_treino), len(MNIST_teste))"
      ],
      "metadata": {
        "id": "HVZJvV7QFco3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30b8c5e-d843-43fd-b9bb-39b36743c07b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(MNIST_teste)"
      ],
      "metadata": {
        "id": "Htmliv9hGjfi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dd53ada-ac59-4bc5-ef7f-7196e660dd1a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.mnist.MNIST"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MNIST_teste[0]"
      ],
      "metadata": {
        "id": "Vauu5MvDGsW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "023204e7-7aae-4cb9-9978-669ad98af108"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3294, 0.7255,\n",
              "           0.6235, 0.5922, 0.2353, 0.1412, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8706, 0.9961,\n",
              "           0.9961, 0.9961, 0.9961, 0.9451, 0.7765, 0.7765, 0.7765, 0.7765,\n",
              "           0.7765, 0.7765, 0.7765, 0.7765, 0.6667, 0.2039, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2627, 0.4471,\n",
              "           0.2824, 0.4471, 0.6392, 0.8902, 0.9961, 0.8824, 0.9961, 0.9961,\n",
              "           0.9961, 0.9804, 0.8980, 0.9961, 0.9961, 0.5490, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0667, 0.2588, 0.0549, 0.2627, 0.2627,\n",
              "           0.2627, 0.2314, 0.0824, 0.9255, 0.9961, 0.4157, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.3255, 0.9922, 0.8196, 0.0706, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0863, 0.9137, 1.0000, 0.3255, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.5059, 0.9961, 0.9333, 0.1725, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.2314, 0.9765, 0.9961, 0.2431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.5216, 0.9961, 0.7333, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353,\n",
              "           0.8039, 0.9725, 0.2275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4941,\n",
              "           0.9961, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2941, 0.9843,\n",
              "           0.9412, 0.2235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.8667, 0.9961,\n",
              "           0.6510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.7961, 0.9961, 0.8588,\n",
              "           0.1373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1490, 0.9961, 0.9961, 0.3020,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.1216, 0.8784, 0.9961, 0.4510, 0.0039,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.5216, 0.9961, 0.9961, 0.2039, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.2392, 0.9490, 0.9961, 0.9961, 0.2039, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.4745, 0.9961, 0.9961, 0.8588, 0.1569, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.4745, 0.9961, 0.8118, 0.0706, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 7)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(MNIST_teste[0])"
      ],
      "metadata": {
        "id": "7sDahqwTGp6H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "031f20e2-b221-4bc6-edd6-9eaa87a95983"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(MNIST_teste[0][0])"
      ],
      "metadata": {
        "id": "2igOKoOVHBAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f330802a-aebd-48a7-f6b3-2eec825ba818"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(MNIST_teste[0][0])"
      ],
      "metadata": {
        "id": "ROK9gEqaHDyT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ce7f0e2-caeb-41c7-b112-b288f70d20e6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MNIST_teste[0][0]"
      ],
      "metadata": {
        "id": "uGRlP59BG7wn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23d74bc4-c101-4e79-ef3b-31e8b7be9eab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3294, 0.7255,\n",
              "          0.6235, 0.5922, 0.2353, 0.1412, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8706, 0.9961,\n",
              "          0.9961, 0.9961, 0.9961, 0.9451, 0.7765, 0.7765, 0.7765, 0.7765,\n",
              "          0.7765, 0.7765, 0.7765, 0.7765, 0.6667, 0.2039, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2627, 0.4471,\n",
              "          0.2824, 0.4471, 0.6392, 0.8902, 0.9961, 0.8824, 0.9961, 0.9961,\n",
              "          0.9961, 0.9804, 0.8980, 0.9961, 0.9961, 0.5490, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0667, 0.2588, 0.0549, 0.2627, 0.2627,\n",
              "          0.2627, 0.2314, 0.0824, 0.9255, 0.9961, 0.4157, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.3255, 0.9922, 0.8196, 0.0706, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0863, 0.9137, 1.0000, 0.3255, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.5059, 0.9961, 0.9333, 0.1725, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.2314, 0.9765, 0.9961, 0.2431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.5216, 0.9961, 0.7333, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353,\n",
              "          0.8039, 0.9725, 0.2275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4941,\n",
              "          0.9961, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2941, 0.9843,\n",
              "          0.9412, 0.2235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.8667, 0.9961,\n",
              "          0.6510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.7961, 0.9961, 0.8588,\n",
              "          0.1373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.1490, 0.9961, 0.9961, 0.3020,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.1216, 0.8784, 0.9961, 0.4510, 0.0039,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.5216, 0.9961, 0.9961, 0.2039, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.2392, 0.9490, 0.9961, 0.9961, 0.2039, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.4745, 0.9961, 0.9961, 0.8588, 0.1569, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.4745, 0.9961, 0.8118, 0.0706, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000]]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MNIST_teste[0][0][0].shape"
      ],
      "metadata": {
        "id": "8vPDD_jzXMtb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c995589-56d9-48a0-b050-1b8a71721c4f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MNIST_teste[0][0][0].shape[0]"
      ],
      "metadata": {
        "id": "Ir5FJ1zqXIxs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35399e3c-e633-4024-a952-8fca7477e4da"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MNIST_teste[0][0][0].shape[0] * MNIST_teste[0][0][0].shape[1]"
      ],
      "metadata": {
        "id": "CP1j0RDxHHx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27967ee4-38a4-444b-87c7-b28677a2c69f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imagem, rotulo = MNIST_treino[11111]\n",
        "\n",
        "imshow(imagem[0])\n",
        "print(rotulo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "wna58216GYmr",
        "outputId": "e65b506a-0092-457c-f218-007ae1fe54d8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "    'batch_size':       5,    #quantidade de amostras por iteração\n",
        "    'num_threads':      4,    #número de threads do DataLoader\n",
        "    #número real de batches = 20 (tamanho de cada batch * quantidade de threads)\n",
        "    'num_classes':      len(MNIST_teste.classes),\n",
        "    'taxa_aprendizado': 1e-4, #\n",
        "    'weight_decay':     5e-4, #\n",
        "    'num_epochs':       30    #\n",
        "}\n",
        "neurons = {\n",
        "    'input_size':   1 * 28 * 28, #dimensão de entrada (imagens de 28x28 bits com 1 canal de cor. precisa ser achatado para uma única dimensão)\n",
        "    'hidden_size':  128, # dimensão escondida, hiperparâmetro\n",
        "    'out_size':     args['num_classes']\n",
        "}"
      ],
      "metadata": {
        "id": "QAJuD0uXFTYN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treino_loader = DataLoader(MNIST_treino,\n",
        "                          batch_size = args['batch_size'],\n",
        "                          shuffle = True,\n",
        "                          num_workers = args['num_threads'])\n",
        "\n",
        "teste_loader = DataLoader(MNIST_teste,\n",
        "                          batch_size = args['batch_size'],\n",
        "                          shuffle = True,\n",
        "                          num_workers = args['num_threads'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVHen7lHB5o6",
        "outputId": "9ec5dc5e-1f51-4667-a00c-333787f957fe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MNIST_MLP(nn.Module):\n",
        "  #Definição da nossa própria multi-layered perceptron\n",
        "  def __init__(self, input_size, hidden_size, out_size):\n",
        "    super(MNIST_MLP, self).__init__()\n",
        "\n",
        "    #Definição das camadas e das funções de ativação intermediárias\n",
        "    # aqui escolhemos duas redes lineares e como funções de ativação, ReLU duas vezes\n",
        "    self.features  = nn.Sequential(\n",
        "                        nn.Linear(input_size, hidden_size),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Linear(hidden_size, hidden_size),\n",
        "                        nn.ReLU())\n",
        "    #A de saída também será linear\n",
        "    self.out     = nn.Linear(hidden_size, out_size)\n",
        "    self.softmax = nn.Softmax()\n",
        "    #Como estamos lidando com um processo de classificação, passaremos por um softmax\n",
        "\n",
        "  def forward(self, input):\n",
        "    #Define a computação de cada chamada\n",
        "    input = input.view(input.size(0), -1) #Linearizando a entrada\n",
        "\n",
        "    feature = self.features(input)\n",
        "    output  = self.softmax(self.out(feature))\n",
        "\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "dSAazYaWF0D8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rede = MNIST_MLP(neurons['input_size'], neurons['hidden_size'], neurons['out_size']).to('cuda')\n",
        "print(rede)"
      ],
      "metadata": {
        "id": "_ntsjRwNeGJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f805e47a-b1f2-4434-ec60-b0ff52df8e6f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST_MLP(\n",
            "  (features): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (out): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (softmax): Softmax(dim=None)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss().to('cuda')"
      ],
      "metadata": {
        "id": "P2rNLzLdfLBD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(rede.parameters(), lr=args['taxa_aprendizado'], weight_decay=args['weight_decay'])\n",
        "#Pesquisar sobre pq Adam (sei leigamente que é mt bom)"
      ],
      "metadata": {
        "id": "2XN1UeCMboGs"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def treina(train_set, rede, num_epochs):\n",
        "  rede.train() #modo treino\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    start = time()\n",
        "\n",
        "    epoch_loss = []\n",
        "    for batch in train_set:\n",
        "\n",
        "      dado, rotulo = batch\n",
        "\n",
        "      dado = dado.to('cuda')\n",
        "      rotulo = rotulo.to('cuda')\n",
        "\n",
        "      # Forward\n",
        "      pred = rede(dado)\n",
        "      loss = criterion(pred, rotulo) #CrossEntropy indicado para classificação multiclasses\n",
        "      epoch_loss.append(loss.cpu().item())\n",
        "\n",
        "      # Backward\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    epoch_loss = np.asarray(epoch_loss)\n",
        "    end = time()\n",
        "\n",
        "    print(\"Epoca %d, Loss: %.4f +\\- %.4f, Tempo: %.2f\" % (epoch, epoch_loss.mean(), epoch_loss.std(), end-start))\n",
        "\n",
        "    return epoch_loss.mean()\n"
      ],
      "metadata": {
        "id": "DP73s473cvhM"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def valida(teste_set, rede, num_epochs):\n",
        "  rede.eval() #modo avaliação\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    start = time()\n",
        "\n",
        "    epoch_loss = []\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with no_grad():\n",
        "\n",
        "      for batch in teste_set:\n",
        "\n",
        "        dado, rotulo = batch\n",
        "\n",
        "        dado = dado.to('cuda')\n",
        "        rotulo = rotulo.to('cuda')\n",
        "\n",
        "        # Forward\n",
        "        pred = rede(dado)\n",
        "        loss = criterion(pred, rotulo)\n",
        "        epoch_loss.append(loss.cpu().item())\n",
        "\n",
        "        y_true.extend(rotulo.cpu().numpy())\n",
        "        y_pred.extend(pred.cpu().numpy())\n",
        "\n",
        "    epoch_loss = np.asarray(epoch_loss)\n",
        "    mse = MSE(y_true, y_pred)\n",
        "    mae = MAE(y_true, y_pred)\n",
        "    end = time()\n",
        "\n",
        "    print(\"Epoca %d, Loss: %.4f +\\- %.4f, Tempo: %.2f\" % (epoch, epoch_loss.mean(), epoch_loss.std(), end-start))\n",
        "\n",
        "    return epoch_loss.mean(), mse, mae"
      ],
      "metadata": {
        "id": "UKyVYB-wbecP"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treino_loss, teste_loss, mse_loss, mae_loss = [], [], [], []\n",
        "for epoch in range(args['num_epochs']):\n",
        "\n",
        "  # Train\n",
        "  treino_loss.append(treina(treino_loader, rede, args['num_epochs']))\n",
        "\n",
        "  # Validate\n",
        "  teste_loss.append(valida(teste_loader, rede, args['num_epochs'])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "D4v4gYJbcYAh",
        "outputId": "e04376c3-aa05-4920-f3e7-bb0833e8ef87"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 0, Loss: 2.3201 +\\- 0.1561, Tempo: 45.55\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-e07195f6013a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# Validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mteste_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalida\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteste_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrede\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-b9d3fc8b2ac2>\u001b[0m in \u001b[0;36mvalida\u001b[0;34m(teste_set, rede, num_epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;36m0.825\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \"\"\"\n\u001b[0;32m--> 442\u001b[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    112\u001b[0m             \"y_true and y_pred have different number of output ({0}!={1})\".format(\n\u001b[1;32m    113\u001b[0m                 \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: y_true and y_pred have different number of output (1!=10)"
          ]
        }
      ]
    }
  ]
}